[["data-cleaning-part-iii-open-refine.html", "Chapter 12 Data Cleaning Part III: Open Refine 12.1 Refinr, Open Refine in R 12.2 Manually cleaning data with Open Refine", " Chapter 12 Data Cleaning Part III: Open Refine Gather ’round kids and let me tell you a tale about your author. In college, your author (Matt Waite) got involved in a project where he mapped crime in the city, looking specifically in the neighborhoods surrounding campus. This was in the mid 1990s. Computers were under powered. Tools were pretty primitive. I was given a database of nearly 50,000 calls for service. And then I learned that addresses were not stored in a standard way. However the officer wrote it down, that’s how it was recorded. What did that mean? It meant the Lincoln (Nebraska) Police Department came up with dozens of ways to say a single place. And since the mapping software needed the addressed to be in a specific form, I had to fix them. For example, I will go to my grave knowing that Lincoln High School’s street address is 2229 J Street. Police officers wrote down LHS, L.H.S., Lincoln HS, Lincoln H.S., LHS (J Street), 2229 J, 2229 J ST, St., Street and on and on and on. That one was relatively easy. The local convenience store chain, with 8 locations around the city, was harder. I had to use the patrol district to locate them. It took me four months to clean up more than 30,000 unique addresses and map them. I tell you this because if I had Open Refine, it would have taken me a week, not four months. Every time I talk about Open Refine, I remember this, and I get mad. Fortunately (unfortunately?) several columns in the PPP loan data we’re working with are flawed in exactly the same way. There are dozens of variations on just “Baltimore.” We’re going to explore two ways into Open Refine: Through R, and through Open Refine itself. 12.1 Refinr, Open Refine in R What is Open Refine? Open Refine is a software program that has tools – algorithms – that find small differences in text and helps you fix them quickly. How Open Refine finds those small differences is through something called clustering. The algorithms behind clustering are not exclusive to Open Refine, so they can be used elsewhere. Enter refinr, a package that contains the same clustering algorithms as Open Refine but all within R. Go ahead and install it if you haven’t already by opening the console and running install.packages(\"refinr\"). Then we can load libraries as we do. library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.3 ✓ purrr 0.3.4 ## ✓ tibble 3.1.1 ✓ dplyr 1.0.5 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 1.4.0 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(refinr) library(janitor) ## ## Attaching package: &#39;janitor&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## chisq.test, fisher.test Let’s load our full Maryland PPP loans data. md_loans &lt;- read_rds(&quot;data/ppp_loans_md.rmd&quot;) Now let’s try and group and count the number of loans by city. To make it a bit more managable, let’s use another string function from stringr and filter for cities that start with the uppercase “A” or lowercase “a” using the function str_detect() with a regular expression. The filter function in the codeblock below says: look in the city column, and pluck out any value that starts with (the “^” symbol means “starts with”) a lowercase “a” OR (the vertical “|,” called a pipe, means OR) an uppercase “A.” md_loans %&gt;% group_by(city) %&gt;% summarise( count=n() ) %&gt;% filter(str_detect(city, &quot;^a|^A&quot;)) %&gt;% arrange(city) ## # A tibble: 62 x 2 ## city count ## &lt;chr&gt; &lt;int&gt; ## 1 ABDULREZAK H ISSAC 1 ## 2 Abell 3 ## 3 ABELL 2 ## 4 aberdeen 3 ## 5 Aberdeen 456 ## 6 ABERDEEN 192 ## 7 Aberdeen Proving Ground 13 ## 8 ABERDEEN PROVING GROUND 2 ## 9 Abereen 1 ## 10 abigdon 2 ## # … with 52 more rows There are lots of problems in this data that will prevent proper grouping and summarizing. We’ve learned several functions to do this manually. By using the Open Refine package for R, refinr, our hope is that it can identify and standardize the data with a little more ease. The first merging technique that’s part of the refinr package we’ll try is the key_collision_merge. The key collision merge function takes each string and extracts the key parts of it. It then puts every key in a bin based on the keys matching. One rule you should follow when using this is: do not overwrite your original fields. Always work on a copy. If you overwrite your original field, how will you know if it did the right thing? How can you compare it to your original data? To follow this, I’m going to mutate a new field called clean_city and put the results of key collision merge there. cleaned_md_loans &lt;- md_loans %&gt;% mutate(city_clean=key_collision_merge(city)) %&gt;% select(id:city, city_clean, everything()) cleaned_md_loans ## # A tibble: 195,865 x 64 ## id name slug amount state address city city_clean zip naics_code ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 9.94e7 TARBIY… tarbi… 149000 MD 6785 B… Elkr… Elkridge 2107… 611110 ## 2 9.94e7 J &amp;AMP… j-amp… 146000 MD 10413 … Unio… Union Bri… 21791 238310 ## 3 9.94e7 DULANE… dulan… 140400 MD 4 Wind… PHOE… Phoenix 2113… 623110 ## 4 9.94e7 QUARTE… quart… 139527 MD 4972 W… Rock… Rockville 20852 311920 ## 5 9.94e7 ORCHAR… orcha… 133400 MD 1855 W… Owin… Owings 2073… 561730 ## 6 9.94e7 FRUITL… fruit… 133000 MD 402 MA… EAST… EASTON 2160… 531120 ## 7 9.94e7 YOUNIV… youni… 130520 MD 5000 T… Oakl… Oakland 2155… 621610 ## 8 9.94e7 FRANKL… frank… 121862 MD 14805 … Spar… Sparks 2115… 812990 ## 9 9.94e7 RACE P… race-… 121100 MD 1 RAIL… WEST… Westminst… 2115… 451110 ## 10 9.94e7 VITAL … vital… 120165 MD 1701 P… Broo… Brookevil… 2083… 541330 ## # … with 195,855 more rows, and 54 more variables: business_type &lt;chr&gt;, ## # race &lt;chr&gt;, gender &lt;chr&gt;, veteran &lt;chr&gt;, non_profit &lt;lgl&gt;, ## # jobs_retained &lt;dbl&gt;, date_approved &lt;date&gt;, lender &lt;chr&gt;, ## # congressional_district &lt;chr&gt;, loan_range_sort_key &lt;lgl&gt;, ## # previous_loan_range &lt;lgl&gt;, previous_name &lt;lgl&gt;, loan_number &lt;dbl&gt;, ## # sba_office_code &lt;dbl&gt;, processing_method &lt;chr&gt;, loan_status &lt;chr&gt;, ## # term &lt;dbl&gt;, sba_guaranty_percentage &lt;dbl&gt;, initial_approval_amount &lt;dbl&gt;, ## # current_approval_amount &lt;dbl&gt;, undisbursed_amount &lt;dbl&gt;, ## # franchise_name &lt;chr&gt;, servicing_lender_location_id &lt;dbl&gt;, ## # servicing_lender_name &lt;chr&gt;, servicing_lender_address &lt;chr&gt;, ## # servicing_lender_city &lt;chr&gt;, servicing_lender_state &lt;chr&gt;, ## # servicing_lender_zip &lt;chr&gt;, rural_urban_indicator &lt;chr&gt;, ## # hubzone_indicator &lt;chr&gt;, business_age_description &lt;chr&gt;, ## # project_city &lt;chr&gt;, project_county_name &lt;chr&gt;, project_state &lt;chr&gt;, ## # project_zip &lt;chr&gt;, utilities_proceed &lt;dbl&gt;, payroll_proceed &lt;dbl&gt;, ## # mortgage_interest_proceed &lt;dbl&gt;, rent_proceed &lt;dbl&gt;, ## # refinance_eidl_proceed &lt;dbl&gt;, health_care_proceed &lt;dbl&gt;, ## # debt_interest_proceed &lt;dbl&gt;, originating_lender_city &lt;chr&gt;, ## # originating_lender_state &lt;chr&gt;, loan_status_date &lt;date&gt;, ## # originating_lender_location_id &lt;dbl&gt;, old_slug &lt;chr&gt;, lmi_indicator &lt;chr&gt;, ## # unmatched_original &lt;lgl&gt;, unmatched_updated &lt;lgl&gt;, ## # previous_jobs_reported &lt;lgl&gt;, ethnicity &lt;chr&gt;, forgiveness_amount &lt;dbl&gt;, ## # forgiveness_date &lt;date&gt; To examine changes refinr made, let’s examine the changes it made to cities that start with the letter “A.” cleaned_md_loans %&gt;% group_by(city_clean, city) %&gt;% summarise( count=n() ) %&gt;% filter(str_detect(city, &quot;^a|^A&quot;)) %&gt;% arrange(city) ## `summarise()` has grouped output by &#39;city_clean&#39;. You can override using the `.groups` argument. ## # A tibble: 62 x 3 ## # Groups: city_clean [38] ## city_clean city count ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 ABDULREZAK H ISSAC ABDULREZAK H ISSAC 1 ## 2 Abell Abell 3 ## 3 Abell ABELL 2 ## 4 Aberdeen aberdeen 3 ## 5 Aberdeen Aberdeen 456 ## 6 Aberdeen ABERDEEN 192 ## 7 Aberdeen Proving Ground Aberdeen Proving Ground 13 ## 8 Aberdeen Proving Ground ABERDEEN PROVING GROUND 2 ## 9 Abereen Abereen 1 ## 10 abigdon abigdon 2 ## # … with 52 more rows It got a bunch of things right. It merged three variations of “Aberdeen” – “aberdeen,”“Aberdeen” and “ABERDEEN” – and it didn’t merge it with “Aberdeen Proving Ground,” which are two distinct places. But it wasn’t smart enough to convert “Abereen” to “Aberdeen.” It also merged “Annapolis” and “ANNAPOLIS” under “Annapolis,” and was smart enough not to merge it with “Annapolis Junction,” which is not the same city. But it wasn’t smart enough to merge “Annapoils” or “Annalpolis.” There’s another merging algorithim that’s part of refinr that works a bit differently, called n_gram_merge(). Let’s try applying that one. cleaned_md_loans &lt;- md_loans %&gt;% mutate(city_clean=n_gram_merge(city)) %&gt;% select(id:city, city_clean, everything()) cleaned_md_loans ## # A tibble: 195,865 x 64 ## id name slug amount state address city city_clean zip naics_code ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 9.94e7 TARBIY… tarbi… 149000 MD 6785 B… Elkr… Elkridge 2107… 611110 ## 2 9.94e7 J &amp;AMP… j-amp… 146000 MD 10413 … Unio… Union Bri… 21791 238310 ## 3 9.94e7 DULANE… dulan… 140400 MD 4 Wind… PHOE… Phoenix 2113… 623110 ## 4 9.94e7 QUARTE… quart… 139527 MD 4972 W… Rock… Rockville 20852 311920 ## 5 9.94e7 ORCHAR… orcha… 133400 MD 1855 W… Owin… Owings 2073… 561730 ## 6 9.94e7 FRUITL… fruit… 133000 MD 402 MA… EAST… EASTON 2160… 531120 ## 7 9.94e7 YOUNIV… youni… 130520 MD 5000 T… Oakl… Oakland 2155… 621610 ## 8 9.94e7 FRANKL… frank… 121862 MD 14805 … Spar… Sparks 2115… 812990 ## 9 9.94e7 RACE P… race-… 121100 MD 1 RAIL… WEST… Westminst… 2115… 451110 ## 10 9.94e7 VITAL … vital… 120165 MD 1701 P… Broo… Brookevil… 2083… 541330 ## # … with 195,855 more rows, and 54 more variables: business_type &lt;chr&gt;, ## # race &lt;chr&gt;, gender &lt;chr&gt;, veteran &lt;chr&gt;, non_profit &lt;lgl&gt;, ## # jobs_retained &lt;dbl&gt;, date_approved &lt;date&gt;, lender &lt;chr&gt;, ## # congressional_district &lt;chr&gt;, loan_range_sort_key &lt;lgl&gt;, ## # previous_loan_range &lt;lgl&gt;, previous_name &lt;lgl&gt;, loan_number &lt;dbl&gt;, ## # sba_office_code &lt;dbl&gt;, processing_method &lt;chr&gt;, loan_status &lt;chr&gt;, ## # term &lt;dbl&gt;, sba_guaranty_percentage &lt;dbl&gt;, initial_approval_amount &lt;dbl&gt;, ## # current_approval_amount &lt;dbl&gt;, undisbursed_amount &lt;dbl&gt;, ## # franchise_name &lt;chr&gt;, servicing_lender_location_id &lt;dbl&gt;, ## # servicing_lender_name &lt;chr&gt;, servicing_lender_address &lt;chr&gt;, ## # servicing_lender_city &lt;chr&gt;, servicing_lender_state &lt;chr&gt;, ## # servicing_lender_zip &lt;chr&gt;, rural_urban_indicator &lt;chr&gt;, ## # hubzone_indicator &lt;chr&gt;, business_age_description &lt;chr&gt;, ## # project_city &lt;chr&gt;, project_county_name &lt;chr&gt;, project_state &lt;chr&gt;, ## # project_zip &lt;chr&gt;, utilities_proceed &lt;dbl&gt;, payroll_proceed &lt;dbl&gt;, ## # mortgage_interest_proceed &lt;dbl&gt;, rent_proceed &lt;dbl&gt;, ## # refinance_eidl_proceed &lt;dbl&gt;, health_care_proceed &lt;dbl&gt;, ## # debt_interest_proceed &lt;dbl&gt;, originating_lender_city &lt;chr&gt;, ## # originating_lender_state &lt;chr&gt;, loan_status_date &lt;date&gt;, ## # originating_lender_location_id &lt;dbl&gt;, old_slug &lt;chr&gt;, lmi_indicator &lt;chr&gt;, ## # unmatched_original &lt;lgl&gt;, unmatched_updated &lt;lgl&gt;, ## # previous_jobs_reported &lt;lgl&gt;, ethnicity &lt;chr&gt;, forgiveness_amount &lt;dbl&gt;, ## # forgiveness_date &lt;date&gt; To examine changes refinr made with this algorithm, let’s again look at cities that start with the letter “A.” Examining Aberdeen and Annapolis, we see there wasn’t a substantial change from the previous method. cleaned_md_loans %&gt;% group_by(city_clean, city) %&gt;% summarise( count=n() ) %&gt;% filter(str_detect(city, &quot;^a|^A&quot;)) %&gt;% arrange(city) ## `summarise()` has grouped output by &#39;city_clean&#39;. You can override using the `.groups` argument. ## # A tibble: 62 x 3 ## # Groups: city_clean [36] ## city_clean city count ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 ABDULREZAK H ISSAC ABDULREZAK H ISSAC 1 ## 2 Abell Abell 3 ## 3 Abell ABELL 2 ## 4 Aberdeen aberdeen 3 ## 5 Aberdeen Aberdeen 456 ## 6 Aberdeen ABERDEEN 192 ## 7 Aberdeen Proving Ground Aberdeen Proving Ground 13 ## 8 Aberdeen Proving Ground ABERDEEN PROVING GROUND 2 ## 9 Abereen Abereen 1 ## 10 Abingdon abigdon 2 ## # … with 52 more rows That’s how you use the Open Refine r package, refinr. Now let’s upload the data to the interactive version of OpenRefine, which really shines at this task. 12.2 Manually cleaning data with Open Refine Open Refine is free software. You should download and install it. Refinr is great for quick things on smaller datasets that you can check to make sure it’s not up to any mischief. For bigger datasets, Open Refine is the way to go. And it has a lot more tools than refinr does (by design). After you install it, run it. Open Refine works in the browser, and the app spins up a small web server visible only on your computer to interact with it. A browser will pop up automatically. You first have to import your data into a project. Click the choose files button and upload a csv of the Maryland loans. After your data is loaded into the app, you’ll get a screen to look over what the data looks like. On the top right corner, you’ll see a button to create the project. Click that. Open Refine has many, many tools. We’re going to use one piece of it, as a tool for data cleaning. To learn how to use it, we’re going to clean the “city” field. First, let’s make a copy of the original city column so that we can preserve the original data while cleaning the new one. Click the dropdown arrow next to the city column, choose “edit column” &gt; Add column based on this column. On the window that pops up, type “city_original” in the “new column name” field. Then hit the OK button. Now, let’s get to work cleaning the city column. Next to the city field name, click the down arrow, then facet, then text facet. After that, a new box will appear on the left. It tells us how many unique cities there are: 1,977. And, there’s a button on the right of the box that says Cluster. Click the cluster button. A new window will pop up, a tool to help us identify things that need to be cleaned, and quickly clean them. The default “method” used is a clustering algorithim called “key collision,” using the fingerprint function. This is the same method we used with the refinr package above. At the top, you’ll see which method was used, and how many clusters that algorithm identified. There are several different methods, each of which work slightly differently and produce different results. Then, below that, you can see what those clusters are. Right away, we can see how useful this program is. It identified 9,903 rows that have some variation on “Silver Spring” in the city field: Silver Spring, SILVER SPRING, silver spring, Silver spring, silver Spring and so on. It proposed changing them all to “Silver Spring.” Using human judgement, you can say if you agree with the cluster. If you do, click the “merge” checkbox. When it merges, the new result will be what it says in New Cell Value. Most often, that’s the row with the most common result. Now begins the fun part: You have to look at all 533 clusters found and decide if they are indeed valid. The key collision method is very good, and very conservative. You’ll find that most of them are usually valid. Be careful! If you merge two things that aren’t supposed to be together, it will change your data in a way that could lead to inaccurate results. When you’re done, click Merge Selected and Re-Cluster. If any new clusters come up, evaluate them. Repeat until either no clusters come up or the clusters that do come up are ones you reject. Now. Try a new method, maybe the “nearest neighbor levenshtein” method. Notice that it finds even more variations of Silver Spring, using a slightly different approach. Rinse and repeat. You’ll keep doing this, and if the dataset is reasonably clean, you’ll find the end. When you’re finished cleaning, click “Merge Selected &amp; Close.” Then, export the data as a csv so you can load it back into R. A question for all data analysts – if the dataset is bad enough, can it ever be cleaned? There’s no good answer. You have to find it yourself. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
